{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "<h1><center>TME 08 \n",
    "    \n",
    "    Features selection \n",
    "    Model selection \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "# Import library"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "pycharm": {
     "is_executing": false,
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.linear_model import ElasticNet\n",
    "from sklearn.svm import LinearSVC\n",
    "from sklearn.feature_selection import SelectFromModel\n",
    "from sklearn import linear_model\n",
    "from sklearn.feature_selection import VarianceThreshold"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "# Import data\n",
    "\n",
    "## Patients with leukemia"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(72, 3562)\n"
     ]
    }
   ],
   "source": [
    "X1 = pd.read_csv('Golub_X',sep=' ',header = None) # Observations\n",
    "y1 = pd.read_csv('Golub_y',sep=' ',header = None) # Classes\n",
    "print(X1.shape)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "## Breast cancer dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(569, 29)\n"
     ]
    }
   ],
   "source": [
    "X = pd.read_csv('Breast.txt',sep=' ',header = None)\n",
    "y2 = X.iloc[:,30] # Classes\n",
    "X2 = X.iloc[:,0:29] # Observations\n",
    "print(X2.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "1. A simple heuristic approach is to delete features whose variance is less then a threshold. Try\n",
    "it (with two different arbitrary thresholds) but do not expect this method to return an optimal\n",
    "performance (although it can be quite efficient on some data sets).\n",
    "http://scikit-learn.org/stable/modules/feature_selection.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(72, 387)\n"
     ]
    }
   ],
   "source": [
    "sel = VarianceThreshold(threshold=(0.05))\n",
    "sel.fit_transform(X1)\n",
    "\n",
    "print(sel.fit_transform(X1).shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(72, 3562)\n",
      "(72, 143)\n"
     ]
    }
   ],
   "source": [
    "X1 = pd.read_csv('Golub_X',sep=' ',header = None) # Observations\n",
    "y1 = pd.read_csv('Golub_y',sep=' ',header = None) # Classes\n",
    "print(X1.shape)\n",
    "\n",
    "sel = VarianceThreshold(threshold=(0.056))\n",
    "print(sel.fit_transform(X1).shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(569, 29)\n",
      "(569, 29)\n"
     ]
    }
   ],
   "source": [
    "X = pd.read_csv('Breast.txt',sep=' ',header = None)\n",
    "y2 = X.iloc[:,30] # Classes\n",
    "X2 = X.iloc[:,0:29] # Observations\n",
    "print(X2.shape)\n",
    "\n",
    "sel = VarianceThreshold(threshold=(0.9))\n",
    "sel.fit_transform(X2);\n",
    "print(X2.shape)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "This method isn't working for the second dataset !"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(569, 29)\n",
      "(569, 29)\n"
     ]
    }
   ],
   "source": [
    "y2 = X.iloc[:,30] # Classes\n",
    "X2 = X.iloc[:,0:29] # Observations\n",
    "print(X2.shape)\n",
    "sel = VarianceThreshold(threshold=(0.001))\n",
    "sel.fit_transform(X2);\n",
    "print(X2.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "This method enable to filter variables that have a very poor variance. By default it removes variance equal to 0. We can add a threshold.\n",
    "\n",
    "We can alos use statistical test to filter our data. The filtred data will be the one that are significant according to the choosed test, here alpha is the threshold at 5%. We can use a chi2, but only with matrix with non-negatives values"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "2. Univariate feature selection with statistical tests to get rid of features which are not statistically significant with respect to the vector of class. Try the SelectFdr function that computes\n",
    "p-values for an estimated false discovery rate.\n",
    "http://scikit-learn.org/stable/modules/generated/sklearn.feature_selection.SelectFdr.\n",
    "html#sklearn.feature_selection.SelectFdr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "from sklearn.feature_selection import SelectFdr, chi2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(569, 24)"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "X_new = SelectFdr(alpha=0.05).fit_transform(X2, y2)\n",
    "X_new.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "Here, 3 colomns where filtred for X2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(72, 545)"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_new = SelectFdr(alpha=0.05).fit_transform(X1, np.ravel(y1))\n",
    "X_new.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "Here, we have more than 3000 colomns that where filtred"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "3. L1-based feature selection is designed to find an optimal solution. The sparsity parameter\n",
    "is important (since it controls the number of non-zero parameters: it too many parameters\n",
    "are kept, no really feature selection; if too few parameters are chosen, it is possible that the\n",
    "accuracy is very poor).\n",
    "\n",
    "    (a) Logistic regression penalized by the L1 penalty term \n",
    "    \n",
    "    $linear_model.Lasso(alpha=alpha)$\n",
    "    \n",
    "    (b) A support vector machine penalized by the L1 penalty term\n",
    "    \n",
    "$LinearSVC(C=C, penalty=\"l1\", dual=False)$\n",
    "\n",
    "    (c) Explore the Elastic Net which is a compromise between the L1 and L2 penalty terms.\n",
    "    \n",
    "$ElasticNet(alpha=alpha, l1_ratio=0.7)$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(72, 3562)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(72, 4)"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X1 = pd.read_csv('Golub_X',sep=' ',header = None) # Observations\n",
    "y1 = pd.read_csv('Golub_y',sep=' ',header = None) # Classes\n",
    "print(X1.shape)\n",
    "\n",
    "a = linear_model.Lasso(alpha=0.05)\n",
    "f1 = a.fit(X1,y1)\n",
    "model = SelectFromModel(f1,prefit=True)\n",
    "Xnew = model.transform(X1)\n",
    "Xnew.shape\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(72, 3562)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(72, 38)"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X1 = pd.read_csv('Golub_X',sep=' ',header = None) # Observations\n",
    "y1 = pd.read_csv('Golub_y',sep=' ',header = None) # Classes\n",
    "print(X1.shape)\n",
    "b = LinearSVC(C = 0.05,penalty=\"l1\", dual=False)\n",
    "f2 = b.fit(X1,np.ravel(y1))\n",
    "m2 = SelectFromModel(f2,prefit=True)\n",
    "Xnew = model.transform(X1)\n",
    "Xnew.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(72, 3562)\n",
      "(72, 14)\n"
     ]
    }
   ],
   "source": [
    "X1 = pd.read_csv('Golub_X',sep=' ',header = None) # Observations\n",
    "y1 = pd.read_csv('Golub_y',sep=' ',header = None) # Classes\n",
    "print(X1.shape)\n",
    "\n",
    "c = ElasticNet(alpha=0.05, l1_ratio=0.7,copy_X=False)\n",
    "f3 = c.fit(X1,y1)\n",
    "m2 = SelectFromModel(f3,prefit=True)\n",
    "Xnew = m2.transform(X1)\n",
    "Xnew.shape\n",
    "print(Xnew.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "### for X2 data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(569, 29)\n"
     ]
    }
   ],
   "source": [
    "y2 = X.iloc[:,30] # Classes\n",
    "X2 = X.iloc[:,0:29] # Observations\n",
    "print(X2.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(569, 29)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/lib/python3.7/site-packages/ipykernel_launcher.py:1: FutureWarning: Method .as_matrix will be removed in a future version. Use .values instead.\n",
      "  \"\"\"Entry point for launching an IPython kernel.\n",
      "/opt/anaconda3/lib/python3.7/site-packages/ipykernel_launcher.py:2: FutureWarning: Method .as_matrix will be removed in a future version. Use .values instead.\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(569, 16)"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y2 = X.as_matrix()[:,30] # Classes\n",
    "X2 = X.as_matrix()[:,0:29] # Observations\n",
    "print(X2.shape)\n",
    "\n",
    "b = linear_model.Lasso(alpha=0.01,copy_X=False)\n",
    "f4 = b.fit(X2,y2)\n",
    "\n",
    "m2 = SelectFromModel(f4,prefit=True)\n",
    "Xnew = m2.transform(X2)\n",
    "Xnew.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(569, 29)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/lib/python3.7/site-packages/ipykernel_launcher.py:1: FutureWarning: Method .as_matrix will be removed in a future version. Use .values instead.\n",
      "  \"\"\"Entry point for launching an IPython kernel.\n",
      "/opt/anaconda3/lib/python3.7/site-packages/ipykernel_launcher.py:2: FutureWarning: Method .as_matrix will be removed in a future version. Use .values instead.\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(569, 10)"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y2 = X.as_matrix()[:,30] # Classes\n",
    "X2 = X.as_matrix()[:,0:29] # Observations\n",
    "print(X2.shape)\n",
    "\n",
    "b = LinearSVC(C = 0.05,penalty=\"l1\", dual=False)\n",
    "f6 = b.fit(X2,y2)\n",
    "m2 = SelectFromModel(f6,prefit=True)\n",
    "Xnew = m2.transform(X2)\n",
    "Xnew.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(569, 29)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/lib/python3.7/site-packages/ipykernel_launcher.py:1: FutureWarning: Method .as_matrix will be removed in a future version. Use .values instead.\n",
      "  \"\"\"Entry point for launching an IPython kernel.\n",
      "/opt/anaconda3/lib/python3.7/site-packages/ipykernel_launcher.py:2: FutureWarning: Method .as_matrix will be removed in a future version. Use .values instead.\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(569, 6)"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y2 = X.as_matrix()[:,30] # Classes\n",
    "X2 = X.as_matrix()[:,0:29] # Observations\n",
    "print(X2.shape)\n",
    "\n",
    "c = ElasticNet(alpha=0.05, l1_ratio=0.7)\n",
    "f8 = c.fit(X2,y2)\n",
    "m2 = SelectFromModel(f8,prefit=True)\n",
    "Xnew = m2.transform(X2)\n",
    "Xnew.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "4. How many features do you keep using these different methods? It is quite normal that each\n",
    "method selects a different number of features."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "All these methods leads to differents results. As you have a huge matrix to analyze, it's crucial to filter our data first. The fist methods using the threshold reduce our matrix from 3562 to 387 for X1 with alpha = 0.05, and to 143 for alpha = 0.056. For X2 with very high or very slow threshold, it dosen't change anything\n",
    "For the second methods the matrix was reduced of 3 columns for X1 and ofmore than 3000 for X2 with alpha = 0.05.\n",
    "Finaly, the L1 feature selection give matrix of 4 rows for X1 with Lasso method (alpha = 0.05), the SVM methods gives 38 (alpha = 0.05) and the Elastic net methods gives 14 for X1. \n",
    "For X2 respectively we have now 14 columns 10 columns and 6 columns for these 3 methods."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "5. What method leads to the best performance (on the given data sets) ?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "If we suppose that the best methods is the ones that filtred more variables (whitch is not always the case, the .  methods works better.\n",
    "The Elastic net methods is supposed to be the better because combine L1 and L2 linear regression penality terms.\n",
    "According to our data, it could be too restrivctive for alpha = 0.05, but as we don't know the meaning of our data, it's complicated to conclude which methods is the better"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  },
  "pycharm": {
   "stem_cell": {
    "cell_type": "raw",
    "metadata": {
     "collapsed": false
    },
    "source": []
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}